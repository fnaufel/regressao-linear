[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Regressão Linear",
    "section": "",
    "text": "% reais % seno\n% vetor\n% vetor e_i\n% blade\n% reverso (til em cima) \\providecommand{}[1]{#1^{~}} % reverso (til à direita) % contração à esq % contração à dir % grau\n% inverso\n% dual\n% undual\n% projeção\n\n\nApresentação\n???"
  },
  {
    "objectID": "simples.html#exemplo-vendas-e-publicidade",
    "href": "simples.html#exemplo-vendas-e-publicidade",
    "title": "\n1  Regressão linear simples\n",
    "section": "\n1.1 Exemplo: vendas e publicidade",
    "text": "1.1 Exemplo: vendas e publicidade\nExemplo baseado no livro James et al. (2021), com dados obtidos de https://www.kaggle.com/datasets/ashydv/advertising-dataset/data.\nEste conjunto de dados contém \\(4\\) colunas:\n\n\ntv: verba (em milhares de dólares) gasta em publicidade na TV;\n\nradio: verba (em milhares de dólares) gasta em publicidade no rádio;\n\njornal: verba (em milhares de dólares) gasta em publicidade em jornais;\n\nvendas: receita das vendas (em milhares de dólares).\n\nCada observação — isto é, cada linha — corresponde a um produto.\nLeitura e limpeza\n\npublicidade &lt;- read_csv(\n  'dados/advertising.csv',\n  show_col_types = FALSE\n) %&gt;% \n  janitor::clean_names() %&gt;% \n  rename(\n    jornal = newspaper,\n    vendas = sales\n  )\n\npublicidade\n\n\n\n  \n\n\n\nDivisão em dados de treino e teste\n\nsplit &lt;- initial_split(publicidade)\ntreino &lt;- training(split)\nteste &lt;- testing(split)\nsplit\n\n&lt;Training/Testing/Total&gt;\n&lt;150/50/200&gt;\n\n\nVendas por verba gasta em TV\nAnálise exploratória\nComeçamos visualizando os dados:\n\ngrafico &lt;- treino %&gt;% \n  ggplot(aes(tv, vendas)) +\n    geom_point()\n\ngrafico\n\n\n\n\n\n\n\nA correlação linear entre vendas e tv é\n\ncor(treino$vendas, treino$tv)\n\n[1] 0,8919795\n\n\nModelo linear\n\nmodelo &lt;- lm(vendas ~ tv, data = treino)\nsummary(modelo)\n\n\nCall:\nlm(formula = vendas ~ tv, data = treino)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-6,0968 -1,5960 -0,0152  1,6301  5,2086 \n\nCoefficients:\n            Estimate Std. Error t value            Pr(&gt;|t|)    \n(Intercept) 7,185427   0,373754   19,23 &lt;0,0000000000000002 ***\ntv          0,053478   0,002228   24,00 &lt;0,0000000000000002 ***\n---\nSignif. codes:  0 '***' 0,001 '**' 0,01 '*' 0,05 '.' 0,1 ' ' 1\n\nResidual standard error: 2,289 on 148 degrees of freedom\nMultiple R-squared:  0,7956,    Adjusted R-squared:  0,7942 \nF-statistic: 576,2 on 1 and 148 DF,  p-value: &lt; 0,00000000000000022\n\n\n\nmodelo_tidy &lt;- tidy(modelo)\nmodelo_tidy\n\n\n\n  \n\n\n\n\nb0 &lt;- modelo_tidy$estimate[1]\nb1 &lt;- modelo_tidy$estimate[2]\n\n\ngrafico +\n  geom_abline(\n    intercept = b0,\n    slope = b1,\n    color = 'blue'\n  )\n\n\n\n\n\n\n\nA equação da reta é\n\\[\n\\begin{aligned}\n  \\widehat{\\text{vendas}}\n  &= \\hat{\\beta_0} + \\hat{\\beta_1} \\cdot \\text{tv} \\\\\n  &= 7{,}19 + 0{,}05 \\cdot \\text{tv}\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "simples.html#teoria",
    "href": "simples.html#teoria",
    "title": "\n1  Regressão linear simples\n",
    "section": "\n1.2 Teoria",
    "text": "1.2 Teoria\nEstimativas \\(\\hat{\\beta_0}\\) e \\(\\hat{\\beta_1}\\)\n\nOs valores achados são estimativas para \\(\\beta_0\\) e \\(\\beta_1\\), baseadas nos dados do conjunto de treino.\nPor isso, os valores de vendas obtidos com esta equação também são estimativas.\nVamos escrever estimativas com o acento circunflexo (chapéu) sobre os símbolos.\nDe onde vêm os valores de \\(\\hat{\\beta_0}\\) e \\(\\hat{\\beta_1}\\)?\nResposta: são os valores que fazem com que a soma dos quadrados das distâncias verticais dos pontos à reta seja a menor possível.\n(Estas distâncias são chamadas de resíduos.)\nConsulte este material para ver os detalhes sobre o cálculo de \\(\\hat{\\beta_0}\\) e \\(\\hat{\\beta_1}\\).\nErros-padrão das estimativas\nVamos pensar nas incertezas associadas aos valores de \\(\\hat{\\beta_0}\\) e \\(\\hat{\\beta_1}\\), com base na excelente discussão em (De Veaux, Velleman e Bock 2016, cap. 25).\nQuais são os fatores que afetam a nossa confiança na reta de regressão?\nMais especificamente, quais os fatores que afetam nossa confiança no valor estimado \\(\\hat\\beta_1\\) (a inclinação da reta)?\nEspalhamento dos pontos em volta da reta\nQuanto mais afastados da reta estiverem os dados, menor a nossa confiança de que a reta captura a variação de uma variável em função da outra.\nObserve a Figura 1.1. O gráfico da esquerda nos dá mais certeza de que uma reta de regressão terá uma inclinação bem próxima da taxa de variação de \\(y\\) em função de \\(x\\) na população.\n\n\nFigura 1.1: Espalhamento dos pontos\n\nEste espalhamento é medido pelo desvio-padrão dos resíduos.\nNo exemplo das vendas, este desvio-padrão dos resíduos é calculado como\n\\[\n\\displaystyle\n\\sqrt{\n\\frac{\\sum_i (\\text{vendas}_i - \\widehat{\\text{vendas}}_i)^2}{n-2}\n}\n\\]\nNo numerador, o valor \\(\\text{vendas}_i - \\widehat{\\text{vendas}}_i\\) é o resíduo da observação \\(i\\).\nAs vendas estimadas para cada valor de tv e os valores dos resíduos podem ser acessados assim:\n\nmodelo_augment &lt;- augment(modelo)\nmodelo_augment %&gt;% \n  select(vendas, tv, .fitted, .resid)\n\n\n\n  \n\n\n\nCalculando o desvio-padrão dos resíduos:\n\nn &lt;- nrow(modelo_augment)\ndp_residuos &lt;- sqrt(sum(modelo_augment$.resid^2) / (n - 2))\ndp_residuos\n\n[1] 2,28897\n\n\nEste valor pode ser obtido na coluna sigma do data frame retornado pela função glance:\n\nmodelo_glance &lt;- glance(modelo)\nmodelo_glance$sigma\n\n[1] 2,28897\n\n\n\n\n\n\n\n\nDesvio-padrão dos resíduos\n\n\n\nNo geral, então, em uma regressão da variável \\(y\\) sobre a variável \\(x\\) com \\(n\\) observações, o desvio-padrão dos resíduos é\n\\[\n\\displaystyle\ns_{\\text{residuos}} =\n\\sqrt{\n\\frac{\\sum_i (y_i - \\widehat{y}_i)^2}{n-2}\n}\n\\]\nPela Figura 1.1 e pelos comentários acima, quanto maior o valor de \\(s_{\\text{residuos}}\\), maior a nossa incerteza.\n\n\nEspalhamento de \\(x\\)\n\nQuanto maior o espalhamento dos valores de \\(x\\), maior nossa confiança na reta de regressão, pois ela estará baseada em uma diversidade maior de valores.\nObserve a Figura 1.2. O gráfico da direita tem um espalhamento maior dos valores de \\(x\\). Uma reta de regressão, ali, parece estar mais bem “ancorada”.\n\n\nFigura 1.2: Espalhamento de \\(x\\)\n\nO espalhamento de \\(x\\) é medido pelo desvio-padrão, que é calculado da maneira usual.\nNo exemplo das vendas, \\(s_x\\), o desvio-padrão de tv é\n\ndp_x &lt;- modelo_augment %&gt;% \n  pull(tv) %&gt;% \n  sd()\n\ndp_x\n\n[1] 84,16717\n\n\n\n\n\n\n\n\nDesvio-padrão dos resíduos\n\n\n\nPela Figura 1.2 e pelos comentários acima, quanto maior o valor de \\(s_x\\), menor a nossa incerteza.\n\n\nQuantidade de dados\nUma reta baseada em mais pontos é mais confiável. Observe a Figura 1.3.\n\n\nFigura 1.3: Quantidade de dados\n\n\n\n\n\n\n\nQuantidade de dados\n\n\n\nPela Figura 1.3 e pelos comentários acima, quanto maior o valor de \\(n\\), menor a nossa incerteza.\n\n\nJuntando tudo\nVimos que\n\nQuanto maior o desvio-padrão dos resíduos (\\(s_{\\text{residuos}}\\)), maior a incerteza.\nQuanto maior o desvio-padrão da variável \\(x\\) (\\(s_x\\)), menor a incerteza.\nQuanto maior a quantidade de dados (\\(n\\)), menor a incerteza.\n\nConcluímos que a incerteza sobre nossa estimativa para \\(\\beta_1\\) (a inclinação da reta) é proporcional aos valores acima da seguinte maneira:\n\\[\nEP(\\beta_1) \\propto \\frac{s_{\\text{residuos}}}{n \\cdot s_x}\n\\]\nonde estamos escrevendo a incerteza como \\(EP(\\beta_1)\\), o erro-padrão de \\(\\beta_1\\).\n\n\n\n\n\n\nErro-padrão de \\(\\beta_1\\)\n\n\n\nA fórmula exata para a incerteza sobre \\(\\beta_1\\) é\n\\[\nEP(\\beta_1) = \\frac{s_{\\text{residuos}}}{\\sqrt{n - 1} \\cdot s_x}\n\\]\n\n\nNo exemplo das vendas, usando as variáveis que já calculamos antes, este erro-padrão é\n\ndp_residuos / (sqrt(n - 1) * dp_x)\n\n[1] 0,002227943\n\n\nEste valor aparece nos resultados de lm como std.error:\n\nmodelo_tidy\n\n\n\n  \n\n\n\nErro-padrão do intercepto\n\n\n\n\n\n\nErro-padrão de \\(\\beta_0\\)\n\n\n\nPara o intercepto \\(\\beta_0\\), o raciocínio é análogo.\nA fórmula exata para a incerteza sobre \\(\\beta_0\\) é\n\\[\nEP(\\beta_0) =\n\\]\n\n\n??? ISLR p. 76\n\n\n\n\n\n\nDe Veaux, R. D., P. F. Velleman, e D. E. Bock. 2016. Stats: Data and Models. 4.ª ed. Pearson Education. https://media.pearsoncmg.com/aw/aw_deveaux_stats_4_2016/websites/statdm4d_comp_web_launch.html.\n\n\nJames, Gareth, Daniela Witten, Trevor Hastie, e Robert Tibshirani. 2021. An Introduction to Statistical Learning: With Applications in R. 2.ª ed. Springer Publishing Company, Incorporated. https://www.statlearning.com/."
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "Referências",
    "section": "",
    "text": "De Veaux, R. D., P. F. Velleman, e D. E. Bock. 2016. Stats: Data and\nModels. 4.ª ed. Pearson Education. https://media.pearsoncmg.com/aw/aw_deveaux_stats_4_2016/websites/statdm4d_comp_web_launch.html.\n\n\nJames, Gareth, Daniela Witten, Trevor Hastie, e Robert Tibshirani. 2021.\nAn Introduction to Statistical Learning: With Applications in\nR. 2.ª ed. Springer Publishing Company, Incorporated. https://www.statlearning.com/."
  }
]